{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXHrNaLdo6SmjvfzyBsRtF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tusharsingh-spring/machine-learning-new/blob/main/CHAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xlaA4oZTn9_V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(\"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\")\n",
        "!pip install -q --upgrade langchain langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "from google.colab import userdata\n",
        "userdata.get('chatkey')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LUQrYxOZo8gb",
        "outputId": "d35386e9-0c77-44d4-919f-126f876bc8fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Access variables\n",
        "chat_key= os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "print(chat_key[4:] + \"....\")  # print only first 4 chars for security\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et5PfUJCpKCW",
        "outputId": "f0b47c9a-9644-437d-bf9c-58323a78a219"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r-v1-a26063f26cb140b20670474da2f048e368cc26c4ab5a876b2f4fa6eb0a4cabf4....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install OpenAI Python package if not already installed\n",
        "!pip install --upgrade openai\n",
        "import time\n",
        "time.sleep(60)\n",
        "# Import required library\n",
        "from openai import OpenAI\n",
        "import getpass\n",
        "import os\n",
        "OPENROUTER_API_KEY= getpass.getpass(\"Enter your OpenRouter API key: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\")\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=OPENROUTER_API_KEY,\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "\n",
        "  extra_body={},\n",
        "  model=\"openai/gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"What is the meaning of life?\"\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scE5RxAFpUlz",
        "outputId": "3525a128-d663-4fcc-d0ca-4e0607212532"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Enter your OpenRouter API key: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··········\n",
            "The meaning of life is a profound and often personal question that has been explored by philosophers, theologians, scientists, and thinkers throughout history. Different cultures, belief systems, and individuals offer various interpretations:\n",
            "\n",
            "1. **Philosophical Perspectives**: Many philosophical traditions ponder the nature of existence and purpose. Existentialists, for instance, suggest that life has no inherent meaning, and it is up to each individual to create their own purpose.\n",
            "\n",
            "2. **Religious Interpretations**: Many religions provide a framework for understanding life's purpose. For example, in Christianity, believers may find meaning through a relationship with God and following the teachings of Jesus. In Buddhism, the focus might be on achieving enlightenment and understanding the nature of suffering.\n",
            "\n",
            "3. **Scientific Views**: From a scientific viewpoint, some argue that life is a product of evolution and natural processes, and any meaning must be constructed by individuals based on their experiences and relationships.\n",
            "\n",
            "4. **Personal Meaning**: For many, the meaning of life may be found in personal fulfillment, relationships, love, creativity, and making a positive impact on others and the world.\n",
            "\n",
            "Ultimately, the search for meaning is a deeply individual journey, and what resonates as meaningful for one person may differ for another.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import CSVLoader\n",
        "def read_doc(directory):\n",
        "  csv_loader = CSVLoader(directory, encoding=\"utf-8\")\n",
        "  documents= csv_loader.load()\n",
        "  return documents"
      ],
      "metadata": {
        "id": "L_ZQs8sntm0m"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Upload CSV file\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "25LZdIE5tvxm",
        "outputId": "a06f94f0-e399-477c-fa89-b9a7dc924a03"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1c964d5-49b2-40cd-bab9-9f772f3135d7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1c964d5-49b2-40cd-bab9-9f772f3135d7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving profiles_summary.csv to profiles_summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load your CSV\n",
        "df = pd.read_csv(\"profiles_summary.csv\")\n",
        "\n",
        "# Count how many times each platform_number occurs\n",
        "counts = df['platform_number'].value_counts()\n",
        "\n",
        "# Keep only rows where platform_number occurs 5 times or less\n",
        "df_filtered = df[df['platform_number'].isin(counts[counts <= 70].index)]\n",
        "\n",
        "# Optionally reset index\n",
        "df_filtered = df_filtered.reset_index(drop=True)\n",
        "\n",
        "# Save filtered CSV (optional)\n",
        "df_filtered.to_csv(\"argo_filtered.csv\", index=False)\n",
        "\n",
        "print(f\"Original rows: {len(df)}, Filtered rows: {len(df_filtered)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDb8I7o1t8_6",
        "outputId": "24668ccb-a08e-4b2b-b044-fafb5069794b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 345, Filtered rows: 345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWKAsFoduWb3",
        "outputId": "8049e451-bf0f-4437-9da9-d366fbba948b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['platform_number', 'cycle_number', 'time', 'latitude', 'longitude',\n",
              "       'temp_mean', 'temp_min', 'temp_max', 'psal_mean', 'psal_min',\n",
              "       'psal_max', 'pres_max', 'nitrate_mean'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Define summary function (keep narrative text, not metadata)\n",
        "def summarize_row(row):\n",
        "    return f\"\"\"\n",
        "On float platform {row['platform_number']} recorded a profile during cycle {row['cycle_number']}\n",
        "The float was located at latitude {row['latitude']} and longitude {row['longitude']} at time {row['time']}.\n",
        "Sensor readings included:\n",
        "- Temperature: mean {row['temp_mean']}°C ,max {row['temp_max']}°C ,min {row['temp_min']}°C\n",
        "- Salinity:  mean {row['psal_mean']}PSU ,max {row['psal_max']}PSU ,min {row['psal_min']}PSU\n",
        "- Pressure:  max  {row['psal_max']}psl\n",
        "- Nitrate:   mean {row['nitrate_mean']} µmol/L\n",
        "\"\"\".strip()\n",
        "\n",
        "# Apply to DataFrame\n",
        "tqdm.pandas()\n",
        "df_filtered[\"summary\"] = df_filtered.progress_apply(summarize_row, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRNJsPQuugUX",
        "outputId": "e42ae30b-0d33-4171-fe53-6ef5c781c48c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 345/345 [00:00<00:00, 19827.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_filtered[\"summary\"].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urlu6JZ8wyR2",
        "outputId": "d0095d81-6638-4ec7-ff1e-471954697364"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    On float platform 1901514 recorded a profile d...\n",
            "1    On float platform 1901759 recorded a profile d...\n",
            "2    On float platform 1901760 recorded a profile d...\n",
            "3    On float platform 1901761 recorded a profile d...\n",
            "4    On float platform 1901762 recorded a profile d...\n",
            "Name: summary, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_data(summaries, chunk_size=800, chunk_overlap=70):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_documents(summaries)\n",
        "  return docs"
      ],
      "metadata": {
        "id": "hPO9IkgexADg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = df_filtered[\"summary\"]\n",
        "docs = [Document(page_content=s, metadata={}) for s in summaries]\n",
        "\n",
        "# Create a text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "\n",
        "# Split the documents into smaller chunks\n",
        "chunked_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"Number of chunks: {len(chunked_docs)}\")\n",
        "print(\"Example chunk:\\n\", chunked_docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkBf3XMfxFV3",
        "outputId": "0267fd04-79f6-4b70-bfd3-76a34d0ad65f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 345\n",
            "Example chunk:\n",
            " On float platform 1901514 recorded a profile during cycle 484.0\n",
            "The float was located at latitude 1.623 and longitude 44.638 at time 2025-01-08 01:24:59.\n",
            "Sensor readings included:\n",
            "- Temperature: mean 25.941°C ,max 25.941°C ,min 25.941°C \n",
            "- Salinity:  mean 0.013PSU ,max 0.013PSU ,min 0.013PSU\n",
            "- Pressure:  max  0.013psl\n",
            "- Nitrate:   mean 27.00142394026461 µmol/L\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])"
      ],
      "metadata": {
        "id": "TiZObYMCxKoR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvsXE6w_xpwx",
        "outputId": "56441be5-983b-4b34-c516-1a4762725106"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x7936f3924290>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7936f381e8d0>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n",
        "\n",
        "from openai import OpenAI\n",
        "import getpass\n",
        "\n",
        "OPENROUTER_KEY = getpass.getpass(\"Enter your OpenRouter API key: \")\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=OPENROUTER_KEY\n",
        ")\n",
        "\n",
        "# Example chat completion\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"openai/gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iT1PGYpxvsc",
        "outputId": "870ded99-d6b3-4e00-d61e-9002764eba37"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Enter your OpenRouter API key: ··········\n",
            "Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "obMatkxk2Zss"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ldUAQ4qP2RiE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ],
      "metadata": {
        "id": "yUkyzv9a2pvn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "3zW9qEPF_A1c"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectorstore(chunked_docs):\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    texts = [str(doc) for doc in chunked_docs]\n",
        "    vectorstore = FAISS.from_texts(text= chunked_docs, embeddings=embeddings)\n",
        "\n"
      ],
      "metadata": {
        "id": "lX6Mpl1I_j5X"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install FAISS CPU version (most compatible)\n",
        "!pip install faiss-cpu\n",
        "\n",
        "# Or if you have GPU support:\n",
        "# !pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1EwO1-8GFEO",
        "outputId": "b53508a2-2ad7-4e44-f9c6-3d9eb69e1520"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First install FAISS\n",
        "!pip install faiss-cpu langchain_community sentence-transformers\n",
        "\n",
        "# Now import and create the vectorstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "def get_vectorstore(chunked_docs):\n",
        "    \"\"\"\n",
        "    Create a FAISS vectorstore from chunked documents with metadata support\n",
        "    \"\"\"\n",
        "    texts = []\n",
        "    metadatas = []\n",
        "\n",
        "    # Process each document chunk\n",
        "    for i, doc in enumerate(chunked_docs):\n",
        "        # Extract text content\n",
        "        if hasattr(doc, 'page_content') and hasattr(doc, 'metadata'):\n",
        "            # LangChain Document object\n",
        "            texts.append(doc.page_content)\n",
        "            # Preserve existing metadata and add some tracking info\n",
        "            metadata = doc.metadata.copy() if hasattr(doc, 'metadata') and doc.metadata else {}\n",
        "            metadata.update({\n",
        "                'chunk_id': f\"chunk_{i}\",\n",
        "                'processed': True,\n",
        "                'embedding_model': 'all-MiniLM-L6-v2'\n",
        "            })\n",
        "            metadatas.append(metadata)\n",
        "\n",
        "        elif isinstance(doc, dict):\n",
        "            # Dictionary format\n",
        "            if 'text' in doc:\n",
        "                texts.append(doc['text'])\n",
        "                metadata = doc.get('metadata', {}).copy()\n",
        "            else:\n",
        "                texts.append(str(doc))\n",
        "                metadata = {}\n",
        "            metadata.update({\n",
        "                'chunk_id': f\"chunk_{i}\",\n",
        "                'processed': True\n",
        "            })\n",
        "            metadatas.append(metadata)\n",
        "\n",
        "        else:\n",
        "            # String or other object\n",
        "            texts.append(str(doc))\n",
        "            metadatas.append({\n",
        "                'chunk_id': f\"chunk_{i}\",\n",
        "                'content_type': 'summary_chunk',\n",
        "                'processed': True,\n",
        "                'embedding_model': 'all-MiniLM-L6-v2'\n",
        "            })\n",
        "\n",
        "    # Use local HuggingFace embeddings (no API required)\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        model_kwargs={'device': 'cpu'},  # Use CPU for compatibility\n",
        "        encode_kwargs={'normalize_embeddings': True}\n",
        "    )\n",
        "\n",
        "    # Create the FAISS vectorstore\n",
        "    vectorstore = FAISS.from_texts(\n",
        "        texts=texts,\n",
        "        embedding=embeddings,\n",
        "        metadatas=metadatas\n",
        "    )\n",
        "\n",
        "    return vectorstore\n",
        "\n",
        "# Now use the function\n",
        "try:\n",
        "    vectorstore = get_vectorstore(chunked_docs)\n",
        "    print(\"✅ Vectorstore created successfully!\")\n",
        "    print(f\"📊 Number of documents: {vectorstore.index.ntotal}\")\n",
        "\n",
        "    # Save it\n",
        "    vectorstore.save_local(\"summary_vectorstore\")\n",
        "    print(\"💾 Vectorstore saved as 'summary_vectorstore'\")\n",
        "\n",
        "    # Test with a sample query\n",
        "    if vectorstore.index.ntotal > 0:\n",
        "        results = vectorstore.similarity_search(\"summary\", k=min(3, vectorstore.index.ntotal))\n",
        "        print(\"\\n🔍 Sample search results:\")\n",
        "        for i, result in enumerate(results):\n",
        "            print(f\"{i+1}. {result.page_content[:100]}...\")\n",
        "            print(f\"   Metadata: {result.metadata}\")\n",
        "            print()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error: {e}\")\n",
        "    print(\"Make sure FAISS is installed: !pip install faiss-cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6xLxkXbAz_Y",
        "outputId": "2570dae8-dd1d-417a-ddf2-286a72f0dbee"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.24)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "✅ Vectorstore created successfully!\n",
            "📊 Number of documents: 345\n",
            "💾 Vectorstore saved as 'summary_vectorstore'\n",
            "\n",
            "🔍 Sample search results:\n",
            "1. On float platform 2902766 recorded a profile during cycle 185.0\n",
            "The float was located at latitude 15...\n",
            "   Metadata: {'chunk_id': 'chunk_95', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "2. On float platform 6903141 recorded a profile during cycle 287.0\n",
            "The float was located at latitude 23...\n",
            "   Metadata: {'chunk_id': 'chunk_281', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "3. On float platform 5906634 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -2...\n",
            "   Metadata: {'chunk_id': 'chunk_244', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After creating your vectorstore, use these methods to inspect it\n",
        "print(\"🔍 Inspecting Vector Database:\")\n",
        "\n",
        "# Check basic info\n",
        "print(f\"Total vectors stored: {vectorstore.index.ntotal}\")\n",
        "print(f\"Vector dimension: {vectorstore.index.d}\")\n",
        "\n",
        "# Get all documents and metadata\n",
        "all_docs = vectorstore.docstore._dict\n",
        "print(f\"Number of documents: {len(all_docs)}\")\n",
        "\n",
        "# Display first few documents with metadata\n",
        "print(\"\\n📄 First 5 documents with metadata:\")\n",
        "for i, (doc_id, doc) in enumerate(list(all_docs.items())[:5]):\n",
        "    print(f\"Document {i+1} (ID: {doc_id}):\")\n",
        "    print(f\"  Content: {doc.page_content[:100]}...\")\n",
        "    print(f\"  Metadata: {doc.metadata}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqSXdzm8EzDC",
        "outputId": "99ddb56a-7cdb-4644-a82d-7160e9bb38f1"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Inspecting Vector Database:\n",
            "Total vectors stored: 345\n",
            "Vector dimension: 384\n",
            "Number of documents: 345\n",
            "\n",
            "📄 First 5 documents with metadata:\n",
            "Document 1 (ID: 361552ea-13f7-499b-a7b5-abfbcc56ccca):\n",
            "  Content: On float platform 1901514 recorded a profile during cycle 484.0\n",
            "The float was located at latitude 1....\n",
            "  Metadata: {'chunk_id': 'chunk_0', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "Document 2 (ID: edc3438c-c9f6-47db-ba47-fb42d09429c3):\n",
            "  Content: On float platform 1901759 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -2...\n",
            "  Metadata: {'chunk_id': 'chunk_1', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "Document 3 (ID: ed251b5b-42f4-498d-ae8e-ef73b90eca81):\n",
            "  Content: On float platform 1901760 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -2...\n",
            "  Metadata: {'chunk_id': 'chunk_2', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "Document 4 (ID: 8ac4208f-5304-4aef-b07b-239127fd2cdb):\n",
            "  Content: On float platform 1901761 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -2...\n",
            "  Metadata: {'chunk_id': 'chunk_3', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "Document 5 (ID: 34db3d7a-7e34-4bdd-b6d9-be8e7e93f48f):\n",
            "  Content: On float platform 1901762 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -2...\n",
            "  Metadata: {'chunk_id': 'chunk_4', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install langchain openai transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfasTDI1_BmR",
        "outputId": "06574005-a884-450d-c13c-93ff6bf619e7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import OpenAI\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "import os\n",
        "\n",
        "# Set your OpenRouter API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "os.environ[\"OPENAI_API_BASE\"] = \"https://openrouter.ai/api/v1\""
      ],
      "metadata": {
        "id": "vxT3JfIwHEyk"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_vectorstore(vectorstore_path=\"summary_vectorstore\"):\n",
        "    \"\"\"Load your saved vectorstore\"\"\"\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    )\n",
        "\n",
        "    vectorstore = FAISS.load_local(\n",
        "        vectorstore_path,\n",
        "        embeddings,\n",
        "        allow_dangerous_deserialization=True\n",
        "    )\n",
        "    return vectorstore\n",
        "\n",
        "# Load your vectorstore\n",
        "vectorstore = load_vectorstore()\n",
        "print(\"✅ Vectorstore loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M03b2l1LHHHE",
        "outputId": "c611ddb1-4275-45b8-d733-834d6953f337"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Vectorstore loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models import ChatOpenAI\n",
        "\n",
        "def get_llm():\n",
        "    \"\"\"Initialize LLM with OpenRouter\"\"\"\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"openai/gpt-4o-mini\",  # or any model supported by OpenRouter\n",
        "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "        openai_api_key=\"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\",\n",
        "        temperature=0.1,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "    return llm"
      ],
      "metadata": {
        "id": "3VEBygkaHOit"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rag_system(vectorstore, llm):\n",
        "    \"\"\"Create a complete RAG system\"\"\"\n",
        "\n",
        "    # Custom prompt template for better responses\n",
        "    prompt_template = \"\"\"you are an Ocean researcher,Use the following pieces of context to answer the question at the end.\n",
        "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Answer:\"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(\n",
        "        template=prompt_template,\n",
        "        input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    # Create retriever\n",
        "    retriever = vectorstore.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\"k\": 4}  # Retrieve 4 most relevant chunks\n",
        "    )\n",
        "\n",
        "    # Create RAG chain\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "    return qa_chain\n",
        "\n",
        "# Initialize LLM (choose one)\n",
        "llm = get_llm()  # Using OpenRouter\n",
        "# llm = get_local_llm()  # Using local model\n",
        "\n",
        "# Create RAG system\n",
        "rag_system = create_rag_system(vectorstore, llm)\n",
        "print(\"✅ RAG system created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-_4lO8pHlPi",
        "outputId": "a67005cc-01d3-4e51-8f71-8c1ea6122360"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ RAG system created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2790383378.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_chat(rag_system, question):\n",
        "    \"\"\"Ask a question to the RAG system\"\"\"\n",
        "    print(f\"Question: {question}\")\n",
        "    print(\" Thinking...\")\n",
        "\n",
        "    try:\n",
        "        result = rag_system({\"query\": question})\n",
        "\n",
        "        print(f\"Answer: {result['result']}\")\n",
        "        print(\"\\n Sources used:\")\n",
        "\n",
        "        for i, source_doc in enumerate(result['source_documents']):\n",
        "            print(f\"{i+1}. {source_doc.page_content[:150]}...\")\n",
        "            print(f\"   Metadata: {source_doc.metadata}\")\n",
        "            print()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Test the RAG system\n",
        "test_questions = [\n",
        "    \"What are the main summaries in this document?\",\n",
        "    \"Can you give me a brief overview of the content?\",\n",
        "    \"What are the key points discussed?\",\n",
        "    \"Summarize the main topics covered.\"\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    rag_chat(rag_system, question)\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JQk3h0vHz1_",
        "outputId": "09f32922-9f9e-4746-91f3-88daf03aef0c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Question: What are the main summaries in this document?\n",
            "🤔 Thinking...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4020677249.py:7: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = rag_system({\"query\": question})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Answer: The document provides profiles recorded by four different float platforms, detailing their locations, sensor readings, and the time of recording. Here are the main summaries:\n",
            "\n",
            "1. **Float Platform 1901760**:\n",
            "   - Location: Latitude -26.7285, Longitude 57.647\n",
            "   - Time: 2025-01-06 21:19:39\n",
            "   - Temperature: Mean 9.94°C, Max 28.52°C, Min 2.44°C\n",
            "   - Salinity: Mean 34.87 PSU, Max 35.69 PSU, Min 34.43 PSU\n",
            "   - Nitrate: Mean 25.40 µmol/L\n",
            "\n",
            "2. **Float Platform 6903141**:\n",
            "   - Location: Latitude 23.0586, Longitude 59.2659\n",
            "   - Time: 2025-01-06 09:48:30\n",
            "   - Temperature: Mean 14.73°C, Max 25.03°C, Min 6.62°C\n",
            "   - Salinity: Mean 35.91 PSU, Max 36.67 PSU, Min 35.17 PSU\n",
            "   - Nitrate: Mean 25.37 µmol/L\n",
            "\n",
            "3. **Float Platform 1902479**:\n",
            "   - Location: Latitude -2.2331, Longitude 78.5921\n",
            "   - Time: 2025-01-02 16:59:17\n",
            "   - Temperature: Mean 8.13°C, Max 28.02°C, Min 2.72°C\n",
            "   - Salinity: Mean 34.91 PSU, Max 35.27 PSU, Min 34.78 PSU\n",
            "   - Nitrate: Mean 25.53 µmol/L\n",
            "\n",
            "4. **Float Platform 6903139**:\n",
            "   - Location: Latitude 12.0003, Longitude 46.3447\n",
            "   - Time: 2025-01-06 19:18:30\n",
            "   - Temperature: Mean 13.72°C, Max 26.30°C, Min 3.80°C\n",
            "   - Salinity: Mean 35.82 PSU, Max 36.45 PSU, Min 34.90 PSU\n",
            "   - Nitrate: Mean 25.44 µmol/L\n",
            "\n",
            "Overall, the document summarizes the environmental conditions (temperature, salinity, and nitrate levels) recorded by the float platforms at different locations and times.\n",
            "\n",
            "📚 Sources used:\n",
            "1. On float platform 1901760 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -26.7285 and longitude 57.647 at time 2025-01-06 21:...\n",
            "   Metadata: {'chunk_id': 'chunk_2', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "2. On float platform 6903141 recorded a profile during cycle 287.0\n",
            "The float was located at latitude 23.058578333333333 and longitude 59.26593166666667 a...\n",
            "   Metadata: {'chunk_id': 'chunk_281', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "3. On float platform 1902479 recorded a profile during cycle 57.0\n",
            "The float was located at latitude -2.2331 and longitude 78.59213 at time 2025-01-02 16:...\n",
            "   Metadata: {'chunk_id': 'chunk_63', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "4. On float platform 6903139 recorded a profile during cycle 291.0\n",
            "The float was located at latitude 12.00032 and longitude 46.34467833333333 at time 202...\n",
            "   Metadata: {'chunk_id': 'chunk_273', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "================================================================================\n",
            "🧠 Question: Can you give me a brief overview of the content?\n",
            "🤔 Thinking...\n",
            "✅ Answer: The provided context includes data from four different oceanographic float platforms that recorded various sensor readings during specific cycles and times. \n",
            "\n",
            "1. **Float Platform 1901760**:\n",
            "   - Location: Latitude -26.7285, Longitude 57.647\n",
            "   - Time: January 6, 2025\n",
            "   - Temperature: Mean 9.94°C, Max 28.52°C, Min 2.44°C\n",
            "   - Salinity: Mean 34.87 PSU, Max 35.69 PSU, Min 34.43 PSU\n",
            "   - Nitrate: Mean 25.40 µmol/L\n",
            "\n",
            "2. **Float Platform 2902768**:\n",
            "   - Location: Latitude 14.518, Longitude 83.161\n",
            "   - Time: January 1, 2025\n",
            "   - Temperature: Mean 11.51°C, Max 28.06°C, Min 2.99°C\n",
            "   - Salinity: Mean 34.74 PSU, Max 35.08 PSU, Min 33.44 PSU\n",
            "   - Nitrate: Mean 25.50 µmol/L\n",
            "\n",
            "3. **Float Platform 4903776**:\n",
            "   - Location: Latitude 9.95, Longitude 88.82\n",
            "   - Time: January 3, 2025\n",
            "   - Temperature: Mean 12.14°C, Max 29.23°C, Min 2.74°C\n",
            "   - Salinity: Mean 34.68 PSU, Max 35.04 PSU, Min 33.27 PSU\n",
            "   - Nitrate: Mean 25.48 µmol/L\n",
            "\n",
            "4. **Float Platform 2903775**:\n",
            "   - Location: Latitude -4.8469, Longitude 73.3471\n",
            "   - Time: January 9, 2025\n",
            "   - Temperature: Mean 9.66°C, Max 27.71°C, Min 3.12°C\n",
            "   - Salinity: Mean 34.90 PSU, Max 35.22 PSU, Min 34.26 PSU\n",
            "   - Nitrate: Mean 25.55 µmol/L\n",
            "\n",
            "Overall, the data includes measurements of temperature, salinity, pressure, and nitrate levels from different oceanic locations, providing insights into the ocean's physical and chemical properties at those times.\n",
            "\n",
            "📚 Sources used:\n",
            "1. On float platform 1901760 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -26.7285 and longitude 57.647 at time 2025-01-06 21:...\n",
            "   Metadata: {'chunk_id': 'chunk_2', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "2. On float platform 2902768 recorded a profile during cycle 179.0\n",
            "The float was located at latitude 14.518 and longitude 83.161 at time 2025-01-01 01:28...\n",
            "   Metadata: {'chunk_id': 'chunk_97', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "3. On float platform 4903776 recorded a profile during cycle 48.0\n",
            "The float was located at latitude 9.95 and longitude 88.81666666666666 at time 2025-01-...\n",
            "   Metadata: {'chunk_id': 'chunk_167', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "4. On float platform 2903775 recorded a profile during cycle 51.0\n",
            "The float was located at latitude -4.846863333333333 and longitude 73.347105 at time 20...\n",
            "   Metadata: {'chunk_id': 'chunk_131', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "================================================================================\n",
            "🧠 Question: What are the key points discussed?\n",
            "🤔 Thinking...\n",
            "✅ Answer: The key points discussed include:\n",
            "\n",
            "1. **Float Platforms and Profiles**: Four different float platforms (3902573, 2903775, 2902206, and 2902768) recorded profiles during specific cycles and times in January 2025.\n",
            "\n",
            "2. **Geographical Locations**: Each float was located at distinct latitudes and longitudes, indicating their positions in the ocean.\n",
            "\n",
            "3. **Sensor Readings**:\n",
            "   - **Temperature**: Each float recorded mean temperatures, with variations in maximum and minimum temperatures across the profiles.\n",
            "   - **Salinity**: Salinity levels were measured in PSU, with each float showing different mean, maximum, and minimum salinity values.\n",
            "   - **Pressure**: Maximum pressure readings were noted for each float.\n",
            "   - **Nitrate Levels**: Mean nitrate concentrations were recorded, showing slight variations among the different floats.\n",
            "\n",
            "4. **Variability**: There is notable variability in temperature, salinity, and nitrate levels among the different floats, reflecting the diverse oceanographic conditions in the areas where they were deployed.\n",
            "\n",
            "📚 Sources used:\n",
            "1. On float platform 3902573 recorded a profile during cycle 35.0\n",
            "The float was located at latitude 9.433333333333334 and longitude 66.8 at time 2025-01-...\n",
            "   Metadata: {'chunk_id': 'chunk_153', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "2. On float platform 2903775 recorded a profile during cycle 51.0\n",
            "The float was located at latitude -4.846863333333333 and longitude 73.347105 at time 20...\n",
            "   Metadata: {'chunk_id': 'chunk_131', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "3. On float platform 2902206 recorded a profile during cycle 323.0\n",
            "The float was located at latitude 9.224 and longitude 70.413 at time 2025-01-05 06:16:...\n",
            "   Metadata: {'chunk_id': 'chunk_87', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "4. On float platform 2902768 recorded a profile during cycle 179.0\n",
            "The float was located at latitude 14.518 and longitude 83.161 at time 2025-01-01 01:28...\n",
            "   Metadata: {'chunk_id': 'chunk_97', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "================================================================================\n",
            "🧠 Question: Summarize the main topics covered.\n",
            "🤔 Thinking...\n",
            "✅ Answer: The main topics covered include the recorded profiles of oceanographic data from four different float platforms, detailing their locations (latitude and longitude), timestamps, and sensor readings for temperature, salinity, pressure, and nitrate levels. Each profile provides mean, maximum, and minimum values for these parameters, highlighting variations in ocean conditions at different geographical locations and times.\n",
            "\n",
            "📚 Sources used:\n",
            "1. On float platform 1901760 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -26.7285 and longitude 57.647 at time 2025-01-06 21:...\n",
            "   Metadata: {'chunk_id': 'chunk_2', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "2. On float platform 2902768 recorded a profile during cycle 179.0\n",
            "The float was located at latitude 14.518 and longitude 83.161 at time 2025-01-01 01:28...\n",
            "   Metadata: {'chunk_id': 'chunk_97', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "3. On float platform 2903775 recorded a profile during cycle 51.0\n",
            "The float was located at latitude -4.846863333333333 and longitude 73.347105 at time 20...\n",
            "   Metadata: {'chunk_id': 'chunk_131', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "4. On float platform 1901761 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -28.7908 and longitude 37.6232 at time 2025-01-03 23...\n",
            "   Metadata: {'chunk_id': 'chunk_3', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions = [\n",
        "    \"whats the location of platform 1901514 \"\n",
        "\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    rag_chat(rag_system, question)\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQqF6TofIOdU",
        "outputId": "643cbd9b-3b78-461f-9a4b-a4506a717c8c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Question: whats the location of platform 1901514 \n",
            "🤔 Thinking...\n",
            "✅ Answer: The location of platform 1901514 is at latitude 1.623 and longitude 44.638.\n",
            "\n",
            "📚 Sources used:\n",
            "1. On float platform 1901514 recorded a profile during cycle 484.0\n",
            "The float was located at latitude 1.623 and longitude 44.638 at time 2025-01-08 01:24:...\n",
            "   Metadata: {'chunk_id': 'chunk_0', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "2. On float platform 1901919 recorded a profile during cycle 95.0\n",
            "The float was located at latitude -9.2339 and longitude 40.9451 at time 2025-01-09 01:2...\n",
            "   Metadata: {'chunk_id': 'chunk_17', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "3. On float platform 1901760 recorded a profile during cycle 139.0\n",
            "The float was located at latitude -26.7285 and longitude 57.647 at time 2025-01-06 21:...\n",
            "   Metadata: {'chunk_id': 'chunk_2', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "4. On float platform 1901839 recorded a profile during cycle 301.0\n",
            "The float was located at latitude -15.99266 and longitude 78.14982 at time 2025-01-06 ...\n",
            "   Metadata: {'chunk_id': 'chunk_11', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions = [\n",
        "    \"whats the salinity profiles near the equator\"\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    rag_chat(rag_system, question)\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZLOMEZbLVyQ",
        "outputId": "0f2a61d8-f8c2-4fc0-9c9a-4dfe7009a5c1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Question: whats the salinity profiles near the equator\n",
            "🤔 Thinking...\n",
            "✅ Answer: The salinity profiles near the equator, based on the provided data, are as follows:\n",
            "\n",
            "1. Float platform 6903031 (located at latitude -5.6815) recorded a mean salinity of 34.8558 PSU, with a maximum of 35.165 PSU and a minimum of 34.619 PSU.\n",
            "\n",
            "2. Float platform 1902477 (located at latitude -1.4773) recorded a mean salinity of 34.9423 PSU, with a maximum of 35.241 PSU and a minimum of 34.771 PSU.\n",
            "\n",
            "These profiles indicate that the salinity values near the equator are relatively similar, ranging from approximately 34.85 to 34.94 PSU.\n",
            "\n",
            "📚 Sources used:\n",
            "1. On float platform 6903140 recorded a profile during cycle 288.0\n",
            "The float was located at latitude 23.95372833333333 and longitude 62.675043333333335 a...\n",
            "   Metadata: {'chunk_id': 'chunk_278', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "2. On float platform 4903660 recorded a profile during cycle 81.0\n",
            "The float was located at latitude 15.247644500000002 and longitude 60.78712983333333 at...\n",
            "   Metadata: {'chunk_id': 'chunk_163', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "3. On float platform 6903031 recorded a profile during cycle 81.0\n",
            "The float was located at latitude -5.681546666666667 and longitude 50.91607333333333 at...\n",
            "   Metadata: {'chunk_id': 'chunk_264', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "4. On float platform 1902477 recorded a profile during cycle 57.0\n",
            "The float was located at latitude -1.47729 and longitude 61.94829 at time 2025-01-02 12...\n",
            "   Metadata: {'chunk_id': 'chunk_61', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions = [\n",
        "    \"Compare BGC parameter in the arabian sea\"\n",
        "\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    rag_chat(rag_system, question)\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR5jIhewLsbN",
        "outputId": "81c478fe-1722-4cf4-f7cd-6a340bf775e7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Question: Compare BGC parameter in the arabian sea\n",
            "🤔 Thinking...\n",
            "✅ Answer: I don't know.\n",
            "\n",
            "📚 Sources used:\n",
            "1. On float platform 3902339 recorded a profile during cycle 6.0\n",
            "The float was located at latitude -26.02022 and longitude 70.02385 at time 2025-01-06 01...\n",
            "   Metadata: {'chunk_id': 'chunk_148', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "2. On float platform 2903893 recorded a profile during cycle 37.0\n",
            "The float was located at latitude 1.5 and longitude 79.75 at time 2025-01-08 14:18:33.\n",
            "...\n",
            "   Metadata: {'chunk_id': 'chunk_137', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "3. On float platform 2903876 recorded a profile during cycle 6.0\n",
            "The float was located at latitude -23.023288333333333 and longitude 49.79074166666667 at...\n",
            "   Metadata: {'chunk_id': 'chunk_134', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "4. On float platform 2902185 recorded a profile during cycle 337.0\n",
            "The float was located at latitude -20.866 and longitude 60.765 at time 2025-01-07 03:2...\n",
            "   Metadata: {'chunk_id': 'chunk_84', 'processed': True, 'embedding_model': 'all-MiniLM-L6-v2'}\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions = [\n",
        "    \"compare BGC prameter between agro floats\"\n",
        "\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    rag_chat(rag_system, question)\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5txLMnEL6CJ",
        "outputId": "8f1db6fa-84a7-4cc9-c5d4-3709576cb631"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧠 Question: compare BGC prameter between agro floats\n",
            "🤔 Thinking...\n",
            "❌ Error: Error code: 401 - {'error': {'message': 'User not found.', 'code': 401}}\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}